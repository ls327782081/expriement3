import logging
import os
import re
import time
import gc
import json
import numpy as np
import pandas as pd
import torch
import requests
from PIL import Image
from io import BytesIO
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModel, CLIPProcessor, CLIPModel
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from config import config
import tqdm
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional


# å›ºå®šéšæœºç§å­
def set_seed(seed):
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)


set_seed(config.seed)


# ç¦»çº¿æå–å¤šæ¨¡æ€ç‰¹å¾ï¼ˆé€‚é…L4ï¼Œé¿å…å®æ—¶ç¼–ç ï¼‰
class AmazonBooksProcessor:
    def __init__(self,
                 data_dir: str,
                 quick_mode: bool = False,
                 min_interactions: int = 5,
                 min_items: int = 5,
                 max_users: Optional[int] = None,
                 max_items: Optional[int] = None,
                 bert_model: str = "bert-base-uncased",
                 clip_model: str = "openai/clip-vit-base-patch32",
                 device: str = "auto",
                 use_cache: bool = True,
                 cache_dir: Optional[str] = None,
                 logger: Optional[logging.Logger] = None,
                 **kwargs):
        """
        åˆå§‹åŒ–Amazon Booksæ•°æ®é›†å¤„ç†å™¨
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            quick_mode: æ˜¯å¦ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆå‡å°‘æ•°æ®é‡ï¼‰
            min_interactions: ç”¨æˆ·æœ€å°äº¤äº’æ¬¡æ•°
            min_items: å•†å“æœ€å°äº¤äº’æ¬¡æ•°
            max_users: æœ€å¤§ç”¨æˆ·æ•°
            max_items: æœ€å¤§å•†å“æ•°
            bert_model: BERTæ¨¡å‹åç§°
            clip_model: CLIPæ¨¡å‹åç§°
            device: è®¡ç®—è®¾å¤‡
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            cache_dir: ç¼“å­˜ç›®å½•
            logger: æ—¥å¿—è®°å½•å™¨
            **kwargs: å…¶ä»–å‚æ•°
        """
        # è®¾ç½®æ—¥å¿—è®°å½•å™¨
        self.logger = logger if logger is not None else logging.getLogger(__name__)
        
        # åŸºæœ¬é…ç½®
        self.data_dir = Path(data_dir)
        self.quick_mode = quick_mode
        self.min_interactions = min_interactions
        self.min_items = min_items
        self.max_users = max_users
        self.max_items = max_items
        self.bert_model_name = bert_model
        self.clip_model_name = clip_model
        self.use_cache = use_cache
        
        # è®¾ç½®è®¾å¤‡
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
            
        self.logger.info(f"Using device: {self.device}")
        
        # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        self.cache_dir = Path(cache_dir) if cache_dir else self.data_dir / "cache"
        self.cache_manager = None  # å¯ä»¥æ ¹æ®éœ€è¦å®ç°ç¼“å­˜ç®¡ç†å™¨
        
        # åˆå§‹åŒ–é¢„è®­ç»ƒæ¨¡å‹
        self._init_pretrained_models()
        
        # å…¶ä»–å‚æ•°
        self.kwargs = kwargs
        
    def _init_pretrained_models(self):
        """åˆå§‹åŒ–é¢„è®­ç»ƒæ¨¡å‹"""
        self.logger.info("Initializing pre-trained models...")
        
        # åˆå§‹åŒ–BERTæ¨¡å‹å’Œåˆ†è¯å™¨
        self.logger.info(f"Loading BERT model: {self.bert_model_name}")
        self.bert_tokenizer = AutoTokenizer.from_pretrained(self.bert_model_name)
        self.bert_model = AutoModel.from_pretrained(self.bert_model_name).to(self.device)
        self.bert_model.eval()
        
        # åˆå§‹åŒ–CLIPæ¨¡å‹å’Œå¤„ç†å™¨
        self.logger.info(f"Loading CLIP model: {self.clip_model_name}")
        self.clip_processor = CLIPProcessor.from_pretrained(self.clip_model_name)
        self.clip_model = CLIPModel.from_pretrained(self.clip_model_name).to(self.device)
        self.clip_model.eval()
        
        self.logger.info("Pre-trained models initialized successfully")
        
    def _log_memory_usage(self, context: str = ""):
        """è®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1024**3  # GB
            cached = torch.cuda.memory_reserved() / 1024**3   # GB
            self.logger.info(f"{context} - GPU Memory: {allocated:.2f}GB allocated, {cached:.2f}GB cached")
    
    def load_reviews(self) -> Tuple[pd.DataFrame, Dict[str, int], Dict[str, int]]:
        """åŠ è½½è¯„è®ºæ•°æ®"""
        self.logger.info("Loading reviews data...")
        
        # ä»HuggingFaceåŠ è½½æ•°æ®
        self.logger.info("Loading reviews from HuggingFace...")
        review_dataset = load_dataset(
            "McAuley-Lab/Amazon-Reviews-2023",
            name="raw_review_Books",
            split="full",
            trust_remote_code=True
        )
        
        # è½¬æ¢ä¸ºDataFrame
        reviews = []
        for review in review_dataset:
            reviews.append({
                'user_id': review.get('reviewerID', ''),
                'item_id': review.get('asin', ''),
                'rating': review.get('overall', 0),
                'timestamp': review.get('timestamp', 0),
                'title': review.get('title', ''),
                'text': review.get('text', ''),
                'verified_purchase': review.get('verified_purchase', False),
                'helpful_vote': review.get('helpful_vote', 0)
            })
            
        df = pd.DataFrame(reviews)
        self.logger.info(f"Loaded {len(df)} reviews")
        
        # æ•°æ®æ¸…æ´—ï¼ˆè¿”å›dfå’Œmappingsï¼‰
        df, user_mapping, item_mapping = self._clean_reviews_data(df)
        
        return df, user_mapping, item_mapping
    
    def _clean_reviews_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, int], Dict[str, int]]:
        """
        æ¸…æ´—è¯„è®ºæ•°æ®
        
        Returns:
            tuple: (cleaned_df, user_mapping, item_mapping)
        """
        self.logger.info("Cleaning reviews data...")
        
        original_size = len(df)
        
        # ç§»é™¤ç¼ºå¤±å…³é”®å­—æ®µçš„è®°å½•
        df = df.dropna(subset=['user_id', 'item_id', 'rating'])
        
        # è¿‡æ»¤è¯„åˆ†èŒƒå›´
        df = df[(df['rating'] >= 1) & (df['rating'] <= 5)]
        
        # è¿‡æ»¤ç”¨æˆ·å’Œå•†å“çš„æœ€å°äº¤äº’æ¬¡æ•°
        user_counts = df['user_id'].value_counts()
        item_counts = df['item_id'].value_counts()
        
        valid_users = user_counts[user_counts >= self.min_interactions].index
        valid_items = item_counts[item_counts >= self.min_items].index
        
        df = df[df['user_id'].isin(valid_users) & df['item_id'].isin(valid_items)]
        
        # é™åˆ¶ç”¨æˆ·å’Œå•†å“æ•°é‡
        if self.max_users:
            top_users = user_counts.head(self.max_users).index
            df = df[df['user_id'].isin(top_users)]
            
        if self.max_items:
            top_items = item_counts.head(self.max_items).index
            df = df[df['item_id'].isin(top_items)]
        
        # åˆ›å»ºç”¨æˆ·å’Œå•†å“çš„è¿ç»­IDæ˜ å°„
        unique_users = df['user_id'].unique()
        unique_items = df['item_id'].unique()
        
        user_mapping = {user_id: i+1 for i, user_id in enumerate(unique_users)}  # ä»1å¼€å§‹ï¼Œ0ä¿ç•™ç»™padding
        item_mapping = {item_id: i+1 for i, item_id in enumerate(unique_items)}  # ä»1å¼€å§‹ï¼Œ0ä¿ç•™ç»™padding
        
        # åº”ç”¨æ˜ å°„
        df['user_id'] = df['user_id'].map(user_mapping)
        df['item_id'] = df['item_id'].map(item_mapping)
        
        # æŒ‰æ—¶é—´æ’åº
        df = df.sort_values(['user_id', 'timestamp'])
        
        self.logger.info(f"Data cleaning completed:")
        self.logger.info(f"  Original size: {original_size}")
        self.logger.info(f"  After cleaning: {len(df)}")
        self.logger.info(f"  Users: {len(user_mapping)}")
        self.logger.info(f"  Items: {len(item_mapping)}")
        
        return df, user_mapping, item_mapping
    
    def load_meta(self) -> pd.DataFrame:
        """åŠ è½½å•†å“å…ƒæ•°æ®"""
        self.logger.info("Loading meta data...")
        
        # ä»HuggingFaceåŠ è½½æ•°æ®
        self.logger.info("Loading meta data from HuggingFace...")
        meta_dataset = load_dataset(
            "McAuley-Lab/Amazon-Reviews-2023",
            name="raw_meta_Books",
            split="full",
            trust_remote_code=True
        )
        
        # è½¬æ¢ä¸ºDataFrame
        meta_data = []
        for item in meta_dataset:
            meta_data.append({
                'item_id': item.get('asin', ''),
                'title': item.get('title', ''),
                'description': item.get('description', []),
                'features': item.get('features', []),
                'categories': item.get('categories', []),
                'image_url': item.get('imageURLHighRes', [])
            })
            
        df = pd.DataFrame(meta_data)
        self.logger.info(f"Loaded {len(df)} meta items")
        
        return df
    
    def _generate_bert_text_features(self, meta_df: pd.DataFrame, item_mapping: Dict[str, int]) -> Dict[int, torch.Tensor]:
        """ä½¿ç”¨BERTç”Ÿæˆæ–‡æœ¬ç‰¹å¾"""
        self.logger.info("Generating BERT text features...")
        
        text_features = {}
        batch_size = 32  # å¢åŠ æ‰¹å¤„ç†å¤§å°ä»¥æé«˜æ•ˆç‡
        
        # å‡†å¤‡æ–‡æœ¬æ•°æ®
        texts_to_process = []
        item_indices = []
        
        for _, row in meta_df.iterrows():
            item_id = row['item_id']
            if item_id not in item_mapping:
                continue
                
            item_idx = item_mapping[item_id]
            
            # ç»„åˆæ–‡æœ¬ä¿¡æ¯
            text_parts = []
            
            # æ ‡é¢˜
            if row['title']:
                text_parts.append(row['title'])
                
            # ç‰¹å¾
            if row['features']:
                text_parts.extend(row['features'][:3])  # å–å‰3ä¸ªç‰¹å¾
                
            # æè¿°
            if row['description']:
                text_parts.extend(row['description'][:2])  # å–å‰2ä¸ªæè¿°
                
            # ç±»åˆ«
            if row['categories']:
                text_parts.append(' '.join(row['categories']))
                
            # åˆå¹¶æ–‡æœ¬å¹¶æˆªæ–­
            combined_text = ' '.join(text_parts)
            # é™åˆ¶æ–‡æœ¬é•¿åº¦ä»¥é€‚åº”BERT
            if len(combined_text) > 500:
                combined_text = combined_text[:500]
                
            texts_to_process.append(combined_text)
            item_indices.append(item_idx)
            
        # æ‰¹å¤„ç†ç”ŸæˆBERTæ–‡æœ¬ç‰¹å¾
        text_features = self._extract_bert_features_batch(texts_to_process, item_indices, batch_size)
        
        self.logger.info(f"Generated BERT text features for {len(text_features)} items")
        
        # è®°å½•å†…å­˜ä½¿ç”¨
        self._log_memory_usage("After BERT feature extraction")
        
        return text_features
    
    def _extract_bert_features_batch(self, texts: List[str], item_indices: List[int], batch_size: int) -> Dict[int, torch.Tensor]:
        """æ‰¹é‡æå–BERTç‰¹å¾"""
        text_features = {}
        
        with torch.no_grad():
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i + batch_size]
                batch_indices = item_indices[i:i + batch_size]
                
                # åˆ†è¯å’Œç¼–ç 
                encoded = self.bert_tokenizer(
                    batch_texts,
                    padding=True,
                    truncation=True,
                    max_length=512,
                    return_tensors='pt'
                )
                
                # ç§»åŠ¨åˆ°è®¾å¤‡
                input_ids = encoded['input_ids'].to(self.device)
                attention_mask = encoded['attention_mask'].to(self.device)
                
                # è·å–BERTè¾“å‡º
                outputs = self.bert_model(input_ids=input_ids, attention_mask=attention_mask)
                
                # ä½¿ç”¨[CLS]æ ‡è®°çš„éšè—çŠ¶æ€ä½œä¸ºæ–‡æœ¬è¡¨ç¤º
                cls_embeddings = outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]
                
                # å­˜å‚¨ç‰¹å¾ï¼ˆç§»åŠ¨åˆ°CPUçœä»½ï¼Œä½¿ç”¨float16å‡å°‘å†…å­˜ï¼‰
                for j, item_idx in enumerate(batch_indices):
                    text_features[item_idx] = cls_embeddings[j].cpu().half()  # float16
                    
                # è¾“å‡ºè¿›åº¦æ—¥å¿—
                if (i // batch_size + 1) % 10 == 0:
                    self.logger.info(f"Processed {i + len(batch_texts)}/{len(texts)} BERT texts")
                    
        return text_features
    
    def _generate_clip_image_features(self, meta_df: pd.DataFrame, item_mapping: Dict[str, int]) -> Dict[int, torch.Tensor]:
        """ä½¿ç”¨CLIPç”Ÿæˆå›¾åƒç‰¹å¾"""
        self.logger.info("Generating CLIP image features...")
        
        image_features = {}
        batch_size = 8  # å›¾åƒå¤„ç†æ‰¹æ¬¡è¾ƒå°
        
        # å‡†å¤‡å›¾åƒURLæ•°æ®
        image_urls = []
        item_indices = []
        
        for _, row in meta_df.iterrows():
            item_id = row['item_id']
            if item_id not in item_mapping:
                continue
                
            item_idx = item_mapping[item_id]
            
            # è·å–å›¾åƒURL
            urls = row['image_url']
            if urls and len(urls) > 0:
                image_urls.append(urls[0])  # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾åƒ
                item_indices.append(item_idx)
            else:
                # å¦‚æœæ²¡æœ‰å›¾åƒURLï¼Œåˆ›å»ºé›¶ç‰¹å¾
                image_features[item_idx] = torch.zeros(512, dtype=torch.float16)
                
        if len(image_urls) == 0:
            self.logger.warning("No valid image URLs found")
            return image_features
            
        # æ‰¹é‡æå–CLIPç‰¹å¾
        image_features.update(self._extract_clip_features_batch(image_urls, item_indices, batch_size))
        
        # æ£€æŸ¥ç¼ºå¤±é¡¹
        valid_items = set(item_indices)
        all_items = set(item_mapping.values())
        missing_items = all_items - valid_items
        
        for item_idx in missing_items:
            image_features[item_idx] = torch.zeros(512, dtype=torch.float16)
            
        if missing_items:
            self.logger.warning(f"Created zero features for {len(missing_items)} items with missing images")
            
        self.logger.info(f"Generated CLIP image features for {len(image_features)} items")
        
        # è®°å½•å†…å­˜ä½¿ç”¨
        self._log_memory_usage("After CLIP image feature extraction")
        
        return image_features
    
    def _extract_clip_features_batch(self, image_urls: List[str], item_indices: List[int], batch_size: int) -> Dict[int, torch.Tensor]:
        """æ‰¹é‡æå–CLIPå›¾åƒç‰¹å¾"""
        clip_features = {}
        
        with torch.no_grad():
            for i in range(0, len(image_urls), batch_size):
                batch_urls = image_urls[i:i + batch_size]
                batch_indices = item_indices[i:i + batch_size]
                
                # ä¸‹è½½å’Œé¢„å¤„ç†å›¾åƒ
                batch_images = []
                valid_indices = []
                
                for j, url in enumerate(batch_urls):
                    try:
                        image = self._download_and_preprocess_image(url)
                        if image is not None:
                            batch_images.append(image)
                            valid_indices.append(batch_indices[j])
                        else:
                            self.logger.warning(f"Failed to download image from {url}, using zero features")
                            # ä¸ºå¤±è´¥çš„å›¾åƒåˆ›å»ºé›¶ç‰¹å¾ï¼ˆä½¿ç”¨float16å‡å°‘å†…å­˜ï¼‰
                            zero_features = torch.zeros(512, dtype=torch.float16)  # CLIPç‰¹å¾ç»´åº¦
                            clip_features[batch_indices[j]] = zero_features
                    except Exception as e:
                        self.logger.error(f"Error processing image from {url}: {e}")
                        zero_features = torch.zeros(512, dtype=torch.float16)
                        clip_features[batch_indices[j]] = zero_features
                
                if not batch_images:
                    continue
                    
                # ä½¿ç”¨CLIPå¤„ç†å™¨é¢„å¤„ç†å›¾åƒ
                inputs = self.clip_processor(images=batch_images, return_tensors="pt").to(self.device)
                
                # è·å–CLIPå›¾åƒç‰¹å¾
                outputs = self.clip_model.get_image_features(**inputs)
                
                # å­˜å‚¨ç‰¹å¾ï¼ˆç§»åŠ¨åˆ°CPUçœä»½ï¼Œä½¿ç”¨float16å‡å°‘å†…å­˜ï¼‰
                for j, item_idx in enumerate(valid_indices):
                    clip_features[item_idx] = outputs[j].cpu().half()  # float16
                    
                # è¾“å‡ºè¿›åº¦æ—¥å¿—
                if (i // batch_size + 1) % 5 == 0:
                    self.logger.info(f"Processed {i + len(batch_urls)}/{len(image_urls)} CLIP images")
                    
        return clip_features
    
    def _download_and_preprocess_image(self, url: str, max_retries: int = 3) -> Optional[Image.Image]:
        """ä¸‹è½½å¹¶é¢„å¤„ç†å›¾åƒ"""
        for attempt in range(max_retries):
            try:
                response = requests.get(url, timeout=10)
                response.raise_for_status()
                
                # æ‰“å¼€å›¾åƒ
                image = Image.open(BytesIO(response.content)).convert("RGB")
                
                # ç®€å•çš„é¢„å¤„ç†ï¼ˆCLIPå¤„ç†å™¨ä¼šå¤„ç†è°ƒæ•´å¤§å°ç­‰ï¼‰
                return image
                
            except Exception as e:
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2  # æŒ‡æ•°é€€é¿ï¼š2, 4, 6ç§’
                    self.logger.warning(f"Download attempt {attempt + 1} failed for {url}: {e}. Retrying in {wait_time}s...")
                    time.sleep(wait_time)
                else:
                    self.logger.error(f"Failed to download {url} after {max_retries} attempts: {e}")
                    raise
                    
        return None
    
    def load_dataset(self) -> Dict[str, Any]:
        """åŠ è½½å®Œæ•´æ•°æ®é›†ï¼ˆæ”¯æŒç¼“å­˜ï¼‰"""
        self.logger.info("Loading Amazon Books dataset...")
        
        # å°è¯•ä»ç¼“å­˜åŠ è½½
        if self.use_cache and self.cache_manager is not None:
            self.logger.info("ğŸ” Checking feature cache...")
            cache_config = {
                'quick_mode': self.quick_mode,
                'min_interactions': self.min_interactions,
                'min_items': self.min_items,
                'max_users': self.max_users,
                'max_items': self.max_items,
                'bert_model': self.bert_model_name,
                'clip_model': self.clip_model_name,
            }
            
            cached_data = self.cache_manager.load(cache_config)
            
            if cached_data is not None:
                self.logger.info("âœ… Loaded features from cache! Skipping BERT/CLIP extraction.")
                return cached_data
            else:
                self.logger.info("âŒ Cache not found. Will extract features and save to cache.")
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ­£å¸¸åŠ è½½æ•°æ®
        start_time = time.time()
        
        # åŠ è½½è¯„è®ºå’Œå…ƒæ•°æ®
        reviews_df, user_mapping, item_mapping = self.load_reviews()
        meta_df = self.load_meta()
        
        # æå–æ–‡æœ¬ç‰¹å¾
        text_features = self._generate_bert_text_features(meta_df, item_mapping)
        
        # æå–å›¾åƒç‰¹å¾
        image_features = self._generate_clip_image_features(meta_df, item_mapping)
        
        # å‡†å¤‡æ•°æ®é›†å­—å…¸
        num_users = len(user_mapping)
        num_items = len(item_mapping)
        
        dataset = {
            'reviews_df': reviews_df,
            'meta_df': meta_df,
            'user_mapping': user_mapping,
            'item_mapping': item_mapping,
            'num_users': num_users,
            'num_items': num_items,
            'text_features': text_features,
            'image_features': image_features
        }
        
        # ä¿å­˜åˆ°ç¼“å­˜
        if self.use_cache and self.cache_manager is not None:
            features_to_cache = {
                'text_features': text_features,
                'image_features': image_features,
                'user_mapping': user_mapping,
                'item_mapping': item_mapping,
                'meta_df': meta_df,
                'reviews_df': reviews_df,
            }
            
            metadata = {
                'num_users': num_users,
                'num_items': num_items,
                'num_interactions': len(reviews_df),
                'created_at': datetime.now().isoformat(),
                **cache_config
            }
            
            try:
                self.cache_manager.save(cache_config, features_to_cache, metadata)
            except Exception as e:
                self.logger.warning(f"Failed to save cache: {e}")
                self.logger.warning("Continuing without cache...")
        
        elapsed_time = time.time() - start_time
        self.logger.info(f"Dataset loaded successfully in {elapsed_time:.2f} seconds")
        
        return dataset
    
    def load_dataset_for_experiment(
        self,
        build_sequences: bool = True,
        min_seq_len: int = 3,
        test_ratio: float = 0.2,
        val_ratio: float = 0.1,
        add_padding_item: bool = True
    ) -> Dict[str, Any]:
        """
        åŠ è½½æ•°æ®é›†ç”¨äºå®éªŒï¼ˆåŒ…æ‹¬åºåˆ—æ„å»ºã€æ•°æ®åˆ†å‰²ç­‰ï¼‰
        
        Args:
            build_sequences: æ˜¯å¦æ„å»ºç”¨æˆ·åºåˆ—
            min_seq_len: æœ€å°åºåˆ—é•¿åº¦
            test_ratio: æµ‹è¯•é›†æ¯”ä¾‹
            val_ratio: éªŒè¯é›†æ¯”ä¾‹
            add_padding_item: æ˜¯å¦ä¸ºpadding item 0é¢„ç•™ä½ç½®
            
        Returns:
            åŒ…å«æ‰€æœ‰å®éªŒæ‰€éœ€æ•°æ®çš„å­—å…¸
        """
        self.logger.info("="*80)
        self.logger.info("Loading dataset for experiment")
        self.logger.info("="*80)
        
        # åŠ è½½åŸºç¡€æ•°æ®é›†
        dataset = self.load_dataset()
        
        # æ„å»ºç”¨æˆ·åºåˆ—
        if build_sequences:
            self.logger.info("Building user sequences...")
            from util import build_user_sequences, split_user_sequences
            
            user_sequences = build_user_sequences(
                dataset['reviews_df'],
                min_seq_len=min_seq_len
            )
            
            # åˆ†å‰²åºåˆ—
            train_sequences, val_sequences, test_sequences = split_user_sequences(
                user_sequences,
                test_ratio=test_ratio,
                val_ratio=val_ratio
            )
            
            # æ·»åŠ åˆ°æ•°æ®é›†
            data = {
                **dataset,
                'train_sequences': train_sequences,
                'val_sequences': val_sequences,
                'test_sequences': test_sequences,
                'user_sequences': user_sequences
            }
            
            # éªŒè¯æ•°æ®èŒƒå›´
            self._validate_data_ranges(data)
        
        # è½¬æ¢ç‰¹å¾æ ¼å¼ï¼ˆæ·»åŠ padding itemï¼‰
        if add_padding_item:
            data = self._convert_features_to_tensors(data)
        
        self.logger.info("="*80)
        self.logger.info("Dataset loaded successfully for experiment")
        self.logger.info("="*80)
        
        return data
    
    def _validate_data_ranges(self, data: Dict[str, Any]):
        """éªŒè¯æ•°æ®èŒƒå›´ï¼Œç¡®ä¿item_idåœ¨æœ‰æ•ˆèŒƒå›´å†…"""
        num_items = data['num_items']
        num_users = data['num_users']
        
        # æ£€æŸ¥æ‰€æœ‰åºåˆ—ä¸­çš„item_id
        all_sequences = {**data['train_sequences'], **data['val_sequences'], **data['test_sequences']}
        
        max_item_id = 0
        max_user_id = 0
        invalid_items = []
        
        for user_id, seq in all_sequences.items():
            max_user_id = max(max_user_id, user_id)
            for item_id in seq['item_indices']:
                max_item_id = max(max_item_id, item_id)
                if item_id > num_items:
                    invalid_items.append((user_id, item_id))
        
        self.logger.info(f"Data validation:")
        self.logger.info(f"  num_users: {num_users}, max_user_id: {max_user_id}")
        self.logger.info(f"  num_items: {num_items}, max_item_id: {max_item_id}")
        
        if invalid_items:
            self.logger.warning(f"Found {len(invalid_items)} invalid item_ids (> num_items={num_items})")
            self.logger.warning(f"First 5 invalid items: {invalid_items[:5]}")
            
            # ä¿®å¤ï¼šå°†è¶…å‡ºèŒƒå›´çš„item_idæˆªæ–­åˆ°æœ‰æ•ˆèŒƒå›´
            self.logger.info(f"Fixing invalid item_ids by clamping to [1, {num_items}]...")
            
            for user_id, seq in all_sequences.items():
                for i, item_id in enumerate(seq['item_indices']):
                    if item_id > num_items:
                        seq['item_indices'][i] = min(item_id, num_items)
    
    def _convert_features_to_tensors(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å°†ç‰¹å¾è½¬æ¢ä¸ºå¼ é‡æ ¼å¼ï¼Œå¹¶æ·»åŠ padding item"""
        num_items = data['num_items']
        
        self.logger.info("Converting features to tensors...")
        
        # å¤„ç†æ–‡æœ¬ç‰¹å¾
        if isinstance(data['text_features'], dict):
            self.logger.info(f"Converting text features to tensor ({num_items} items)...")
            
            # åˆ›å»ºå¼ é‡ï¼ˆ+1ä¸ºpadding item 0é¢„ç•™ä½ç½®ï¼‰
            text_tensor = torch.zeros(num_items + 1, 768, dtype=torch.float16)  # BERTç‰¹å¾ç»´åº¦
            
            # å¡«å……ç‰¹å¾
            for item_idx, feat in data['text_features'].items():
                # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
                if 0 <= item_idx <= num_items:
                    text_tensor[item_idx] = feat
                else:
                    self.logger.warning(f"Skipping invalid item_idx {item_idx} (num_items={num_items})")
            
            data['text_features'] = text_tensor
            self.logger.info(f"âœ… Converted text_features to tensor: {text_tensor.shape}")
            
        elif isinstance(data['text_features'], torch.Tensor):
            # å¦‚æœå·²ç»æ˜¯tensorï¼Œæ£€æŸ¥ç»´åº¦æ˜¯å¦æ­£ç¡®
            current_shape = data['text_features'].shape
            if current_shape[0] == num_items:
                # éœ€è¦æ·»åŠ padding item 0
                self.logger.info(f"Adding padding item 0 to text_features: {current_shape} -> [{num_items+1}, {current_shape[1]}]")
                text_dim = current_shape[1]
                text_tensor = torch.zeros(num_items + 1, text_dim, dtype=data['text_features'].dtype)
                text_tensor[1:] = data['text_features']  # items 1..num_items
                data['text_features'] = text_tensor
                self.logger.info(f"âœ… Added padding item 0 to text_features: {text_tensor.shape}")
            elif current_shape[0] == num_items + 1:
                # å·²ç»åŒ…å«padding item 0
                self.logger.info(f"âœ… text_features already has correct shape: {current_shape}")
            else:
                self.logger.warning(f"âš ï¸ Unexpected text_features shape: {current_shape}, expected [{num_items}] or [{num_items+1}]")
        
        # å¤„ç†å›¾åƒç‰¹å¾
        if isinstance(data['image_features'], dict):
            self.logger.info(f"Converting image features to tensor ({num_items} items)...")
            
            # åˆ›å»ºå¼ é‡ï¼ˆ+1ä¸ºpadding item 0é¢„ç•™ä½ç½®ï¼‰
            image_tensor = torch.zeros(num_items + 1, 512, dtype=torch.float16)  # CLIPç‰¹å¾ç»´åº¦
            
            # å¡«å……ç‰¹å¾
            for item_idx, feat in data['image_features'].items():
                # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
                if 0 <= item_idx <= num_items:
                    image_tensor[item_idx] = feat
                else:
                    self.logger.warning(f"Skipping invalid item_idx {item_idx} (num_items={num_items})")
            
            data['image_features'] = image_tensor
            self.logger.info(f"âœ… Converted image_features to tensor: {image_tensor.shape}")
            
        elif isinstance(data['image_features'], torch.Tensor):
            # å¦‚æœå·²ç»æ˜¯tensorï¼Œæ£€æŸ¥ç»´åº¦æ˜¯å¦æ­£ç¡®
            current_shape = data['image_features'].shape
            if current_shape[0] == num_items:
                # éœ€è¦æ·»åŠ padding item 0
                self.logger.info(f"Adding padding item 0 to image_features: {current_shape} -> [{num_items+1}, {current_shape[1]}]")
                image_dim = current_shape[1]
                image_tensor = torch.zeros(num_items + 1, image_dim, dtype=data['image_features'].dtype)
                image_tensor[1:] = data['image_features']  # items 1..num_items
                data['image_features'] = image_tensor
                self.logger.info(f"âœ… Added padding item 0 to image_features: {image_tensor.shape}")
            elif current_shape[0] == num_items + 1:
                # å·²ç»åŒ…å«padding item 0
                self.logger.info(f"âœ… image_features already has correct shape: {current_shape}")
            else:
                self.logger.warning(f"âš ï¸ Unexpected image_features shape: {current_shape}, expected [{num_items}] or [{num_items+1}]")
        
        self._log_memory_usage("After feature tensor conversion")
        
        return data

class BooksDataset(Dataset):
    def __init__(self, data: Dict[str, Any], feature_type: str = "text"):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            data: åŒ…å«æ‰€æœ‰æ•°æ®çš„å­—å…¸
            feature_type: ç‰¹å¾ç±»å‹ï¼Œ"text"æˆ–"image"æˆ–"multimodal"
        """
        self.data = data
        self.feature_type = feature_type
        
        # è·å–åºåˆ—æ•°æ®
        self.sequences = data.get('train_sequences', {})
        
        # è·å–ç‰¹å¾
        self.text_features = data.get('text_features')
        self.image_features = data.get('image_features')
        
        # åˆ›å»ºç”¨æˆ·åºåˆ—åˆ—è¡¨
        self.user_ids = list(self.sequences.keys())
        self.num_users = len(self.user_ids)
        
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"Initialized dataset with {self.num_users} users, feature_type={feature_type}")
        
    def __len__(self):
        return self.num_users
    
    def __getitem__(self, idx):
        user_id = self.user_ids[idx]
        seq = self.sequences[user_id]
        
        # è·å–ç‰©å“åºåˆ—
        item_indices = seq['item_indices']
        
        # æ ¹æ®ç‰¹å¾ç±»å‹è·å–ç‰¹å¾
        if self.feature_type == "text":
            features = self.text_features[item_indices]
        elif self.feature_type == "image":
            features = self.image_features[item_indices]
        elif self.feature_type == "multimodal":
            # å¤šæ¨¡æ€ï¼šæ‹¼æ¥æ–‡æœ¬å’Œå›¾åƒç‰¹å¾
            text_feat = self.text_features[item_indices]
            image_feat = self.image_features[item_indices]
            features = torch.cat([text_feat, image_feat], dim=1)
        else:
            raise ValueError(f"Unknown feature type: {self.feature_type}")
        
        return {
            'user_id': torch.tensor(user_id, dtype=torch.long),
            'item_indices': torch.tensor(item_indices, dtype=torch.long),
            'features': features,
            'ratings': torch.tensor(seq.get('ratings', [0] * len(item_indices)), dtype=torch.float)
        }


def get_dataloader(data: Dict[str, Any], 
                  feature_type: str = "text",
                  batch_size: int = 32,
                  shuffle: bool = True,
                  num_workers: int = 0,
                  logger=None):
    """
    åˆ›å»ºæ•°æ®åŠ è½½å™¨
    
    Args:
        data: åŒ…å«æ‰€æœ‰æ•°æ®çš„å­—å…¸
        feature_type: ç‰¹å¾ç±»å‹ï¼Œ"text"æˆ–"image"æˆ–"multimodal"
        batch_size: æ‰¹å¤§å°
        shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ®
        num_workers: å·¥ä½œè¿›ç¨‹æ•°
        logger: æ—¥å¿—è®°å½•å™¨
        
    Returns:
        DataLoader: æ•°æ®åŠ è½½å™¨
    """
    if logger is None:
        logger = logging.getLogger("PMAT_Experiment")
        
    dataset = BooksDataset(data, feature_type)
    
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )


# åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨ï¼ˆé¦–æ¬¡è¿è¡Œæ‰§è¡Œï¼‰
if __name__ == "__main__" and not os.path.exists("./data/train.pkl"):
    logger = logging.getLogger("PMAT_Experiment")
    processor = AmazonBooksProcessor(category="Video_Games", logger=logger)
    processor.run()